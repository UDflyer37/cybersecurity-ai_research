{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Yakopcic\n",
    "# University of Dayton\n",
    "# Feb. 1, 2019\n",
    "# CNN for NSL KDD Training\n",
    "\n",
    "##################################################################\n",
    "################# User Input Section #############################\n",
    "##################################################################\n",
    "\n",
    "#######################\n",
    "# Classification Type #\n",
    "#######################\n",
    "\n",
    "# Pick 1, 2, or 3\n",
    "# 1: Same thing we've been doing, two outputs. normal or attack\n",
    "# 2: 5 total outputs, classifing between normal and 4 different subclasses of attack\n",
    "# 3: Full classification, differentiate between normal and all different attack types\n",
    "\n",
    "class_mode = 2\n",
    "\n",
    "###################\n",
    "# Hyperparameters #\n",
    "###################\n",
    "\n",
    "# These  parameters are like global setting for your network\n",
    "num_epochs = 20 #The number of times you will iterate through the dataset\n",
    "                #A higher number will (ussually) produce a more accuracte network but will take longer to train\n",
    "\n",
    "batch_size = 100 #Neural networks can be made more efficient by processing groups of data all at once\n",
    "                #the batch size is how many datasamples will be processed between weight update steps\n",
    "                #lager batches make training faster but possibly less accurate if batches are too big\n",
    "\n",
    "learning_rate = 0.001 #magnitude factor that controls the amount of weight update for each cycle\n",
    "                      #big learning rate - hard to minimize error\n",
    "                      #small learning rate - have to use lots of epochs to minimize error\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "##########################\n",
    "# Neural Network Details #\n",
    "##########################        \n",
    "        \n",
    "#length of the convolution filers being trained in the network\n",
    "filter_size = 5\n",
    "\n",
    "#number of output features after the first convolution layer\n",
    "conv1_features = 12\n",
    "#number of output features after the second convolution layer\n",
    "conv2_features = 24\n",
    "\n",
    "#number of neurons in the middle fully connected layer, the front layer is sazed according to conv outputs \n",
    "# and the back layer is set to have neurons equal to the number of classes\n",
    "hidden_layer = 256        \n",
    "        \n",
    "        \n",
    "\n",
    "################\n",
    "# Data Folders #\n",
    "################\n",
    "        \n",
    "# All neural networks need to load some sort of data to learn, this is the folder from which the script is loading data\n",
    "DATA_PATH = r'C:\\\\Users\\ottoa\\UD Classes\\Cyber Security Research\\\\'\n",
    "\n",
    "# After training, network properties and weights can be saved to the same training process does not need to be repeated\n",
    "# this is the folder where these weights should be saved after training is finished\n",
    "MODEL_STORE_PATH = r'C:\\\\Users\\ottoa\\UD Classes\\Cyber Security Research\\pytorch_models\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header information in the MAT file:\n",
      "['__globals__', '__header__', '__version__', 'kdd_attack_bipolar', 'kdd_attack_classes', 'kdd_data_set', 'kdd_labels']\n",
      "\n",
      "\n",
      "Full KDD Data Shape:  (125973, 39)\n",
      "Full KDD Label Shape:  (125973, 1)\n",
      "Number of classes for the network:  5\n"
     ]
    }
   ],
   "source": [
    "# import pytorch libraries\n",
    "# these libraries hold all the functions we use to build, \n",
    "# train, and test the neural networks\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import the numical python function set, and call these function using 'np' as shorthand\n",
    "import numpy as np\n",
    "\n",
    "#get the load mat function from the scientific python library\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# load the training/testing data\n",
    "x = loadmat(DATA_PATH + 'nsl_kdd_pytorch.mat')\n",
    "\n",
    "#view tags and info in this particular datafile\n",
    "print(\"Header information in the MAT file:\")\n",
    "print(sorted(x.keys()))\n",
    "print(\"\\n\")\n",
    "\n",
    "#we determined that the datawe need was in the 'kdd data set' variable\n",
    "x_data = x['kdd_data_set']\n",
    "\n",
    "# one row in the data is all zeros and this throws off normalization, so lets remove it\n",
    "kdd_42a = x_data[:,0:19]\n",
    "kdd_42b = x_data[:,20:-1]\n",
    "kdd_42 = np.concatenate((kdd_42a,kdd_42b),1)\n",
    "\n",
    "#print the shape of the matrix for assurance\n",
    "print(\"Full KDD Data Shape: \", kdd_42.shape)\n",
    "\n",
    "#find the maximum value for each of the features\n",
    "max_row = kdd_42.max(0)\n",
    "\n",
    "#copy it so was have a matrix the same size as the test data\n",
    "max_grid = np.tile(max_row,(125973,1))\n",
    "\n",
    "#mornalize the data through elemnet-wise division\n",
    "kdd_norm = kdd_42/max_grid\n",
    "\n",
    "#load the labels from the dataset based on what the user selected for class mode\n",
    "if class_mode == 1:\n",
    "    labels = x['kdd_attack_bipolar']\n",
    "if class_mode == 2:\n",
    "    labels = x['kdd_attack_classes']   \n",
    "if class_mode == 3:\n",
    "    labels = x['kdd_labels']\n",
    "\n",
    "#loaded labels are 1: normal and 2: attack\n",
    "#we need 0: normal and 1:attack so 1 is subracted from all data\n",
    "#or we may use for detailed subclasses, but they always start at 1\n",
    "new_labels = labels - 1\n",
    "\n",
    "print(\"Full KDD Label Shape: \", new_labels.shape)\n",
    "\n",
    "num_classes = np.unique(labels).size\n",
    "                #number of possible classifcation options at the network output\n",
    "                #to get this value we see how many unique values are in the label set\n",
    "\n",
    "print(\"Number of classes for the network: \", np.unique(labels).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor:  torch.Size([125973, 1, 39, 1])\n",
      "\n",
      "\n",
      "Label Tensor, 2D array:  tensor([[0, 0, 1,  ..., 0, 1, 0]])\n",
      "Label Tensor, 1D array:  tensor([0, 0, 1,  ..., 0, 1, 0])\n",
      "\n",
      "\n",
      "Shape of label tensor:  torch.Size([125973])\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_P = 125973 #hold the total data length in a convenient varaible\n",
    "\n",
    "P = max_P #pick how many data samples to test\n",
    "\n",
    "\n",
    "y_labels = np.swapaxes(new_labels,0,1)\n",
    "\n",
    "tensor_x = torch.from_numpy(kdd_norm[0:P,:]).float()\n",
    "tensor_y = torch.from_numpy(y_labels[:,0:P]).long()\n",
    "\n",
    "# pytorch expects [b, 3, h, w] where b is batch size, 3 is 3 channels such as RGB, h is data height, and w is data width.\n",
    "#these lines rearrange the data so it matches this format\n",
    "tensor_x = tensor_x.permute(0, 1).unsqueeze(1)\n",
    "tensor_x = tensor_x.unsqueeze(3)\n",
    "\n",
    "print('Shape of data tensor: ',tensor_x.shape)\n",
    "print('\\n')\n",
    "print(\"Label Tensor, 2D array: \", tensor_y)\n",
    "\n",
    "#get rid of the extra bracket set by collapsing the dimension\n",
    "tensor_y = tensor_y.squeeze_()\n",
    "\n",
    "#now see the slightly different 1D array\n",
    "print(\"Label Tensor, 1D array: \", tensor_y)\n",
    "print('\\n')\n",
    "print('Shape of label tensor: ',tensor_y.shape)\n",
    "\n",
    "#create a full dataset object using the data and corresponding labels\n",
    "my_dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y) \n",
    "\n",
    "#create a data loader object, which further formats the data for the neural network\n",
    "#note the data shuffling, this is very important when loading ordered data, because that will incorrectly bias the\n",
    "#network to the last observed data class\n",
    "train_loader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size, shuffle=True) # create your dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 12, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(12, 24, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop_out): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=216, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 12, 39, 1]              72\n",
      "              ReLU-2            [-1, 12, 39, 1]               0\n",
      "         MaxPool2d-3            [-1, 12, 19, 1]               0\n",
      "            Conv2d-4            [-1, 24, 19, 1]           1,464\n",
      "              ReLU-5            [-1, 24, 19, 1]               0\n",
      "         MaxPool2d-6             [-1, 24, 9, 1]               0\n",
      "           Dropout-7                  [-1, 216]               0\n",
      "            Linear-8                  [-1, 256]          55,552\n",
      "            Linear-9                    [-1, 5]           1,285\n",
      "================================================================\n",
      "Total params: 58,373\n",
      "Trainable params: 58,373\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 0.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create the Model\n",
    "\n",
    "\n",
    "#import one more function to get the neural network to work\n",
    "import torch.nn as nn\n",
    "\n",
    "#pad size is determined by filter size according to the following equation\n",
    "pad_size = int((filter_size - 1)/2)\n",
    "\n",
    "#build the model you would like to run\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, conv1_features, kernel_size=(filter_size,1), stride=1, padding=(pad_size,0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(conv1_features, conv2_features, kernel_size=(filter_size,1), stride=1, padding=(pad_size,0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(conv2_features*9, hidden_layer)\n",
    "        self.fc2 = nn.Linear(hidden_layer, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "#store your neural network in the model varaible\n",
    "model = ConvNet()\n",
    "\n",
    "#print details of each layer in the model\n",
    "print(model)\n",
    "\n",
    "#import and run the torch summary function that prints a nice formatted flow of the CNN\n",
    "from torchsummary import summary\n",
    "summary(model,input_size=(1,39,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/1260], Loss: 0.2228, Accuracy: 93.00%\n",
      "Epoch [1/20], Step [200/1260], Loss: 0.2540, Accuracy: 93.00%\n",
      "Epoch [1/20], Step [300/1260], Loss: 0.0799, Accuracy: 97.00%\n",
      "Epoch [1/20], Step [400/1260], Loss: 0.3210, Accuracy: 88.00%\n",
      "Epoch [1/20], Step [500/1260], Loss: 0.0660, Accuracy: 99.00%\n",
      "Epoch [1/20], Step [600/1260], Loss: 0.1664, Accuracy: 95.00%\n",
      "Epoch [1/20], Step [700/1260], Loss: 0.1964, Accuracy: 95.00%\n",
      "Epoch [1/20], Step [800/1260], Loss: 0.2056, Accuracy: 93.00%\n",
      "Epoch [1/20], Step [900/1260], Loss: 0.0911, Accuracy: 96.00%\n",
      "Epoch [1/20], Step [1000/1260], Loss: 0.1317, Accuracy: 95.00%\n",
      "Epoch [1/20], Step [1100/1260], Loss: 0.1148, Accuracy: 95.00%\n",
      "Epoch [1/20], Step [1200/1260], Loss: 0.0789, Accuracy: 98.00%\n",
      "Epoch [2/20], Step [100/1260], Loss: 0.2005, Accuracy: 95.00%\n",
      "Epoch [2/20], Step [200/1260], Loss: 0.0355, Accuracy: 99.00%\n",
      "Epoch [2/20], Step [300/1260], Loss: 0.0836, Accuracy: 98.00%\n",
      "Epoch [2/20], Step [400/1260], Loss: 0.0602, Accuracy: 97.00%\n",
      "Epoch [2/20], Step [500/1260], Loss: 0.1270, Accuracy: 97.00%\n",
      "Epoch [2/20], Step [600/1260], Loss: 0.0597, Accuracy: 97.00%\n",
      "Epoch [2/20], Step [700/1260], Loss: 0.0581, Accuracy: 98.00%\n",
      "Epoch [2/20], Step [800/1260], Loss: 0.0689, Accuracy: 98.00%\n",
      "Epoch [2/20], Step [900/1260], Loss: 0.0377, Accuracy: 99.00%\n",
      "Epoch [2/20], Step [1000/1260], Loss: 0.1229, Accuracy: 97.00%\n",
      "Epoch [2/20], Step [1100/1260], Loss: 0.0643, Accuracy: 98.00%\n",
      "Epoch [2/20], Step [1200/1260], Loss: 0.1398, Accuracy: 96.00%\n",
      "Epoch [3/20], Step [100/1260], Loss: 0.0364, Accuracy: 99.00%\n",
      "Epoch [3/20], Step [200/1260], Loss: 0.0708, Accuracy: 96.00%\n",
      "Epoch [3/20], Step [300/1260], Loss: 0.0629, Accuracy: 98.00%\n",
      "Epoch [3/20], Step [400/1260], Loss: 0.0904, Accuracy: 97.00%\n",
      "Epoch [3/20], Step [500/1260], Loss: 0.0642, Accuracy: 95.00%\n",
      "Epoch [3/20], Step [600/1260], Loss: 0.1165, Accuracy: 97.00%\n",
      "Epoch [3/20], Step [700/1260], Loss: 0.0727, Accuracy: 97.00%\n",
      "Epoch [3/20], Step [800/1260], Loss: 0.0554, Accuracy: 98.00%\n",
      "Epoch [3/20], Step [900/1260], Loss: 0.0464, Accuracy: 99.00%\n",
      "Epoch [3/20], Step [1000/1260], Loss: 0.0406, Accuracy: 99.00%\n",
      "Epoch [3/20], Step [1100/1260], Loss: 0.0461, Accuracy: 98.00%\n",
      "Epoch [3/20], Step [1200/1260], Loss: 0.0535, Accuracy: 99.00%\n",
      "Epoch [4/20], Step [100/1260], Loss: 0.0300, Accuracy: 99.00%\n",
      "Epoch [4/20], Step [200/1260], Loss: 0.0467, Accuracy: 98.00%\n",
      "Epoch [4/20], Step [300/1260], Loss: 0.1008, Accuracy: 96.00%\n",
      "Epoch [4/20], Step [400/1260], Loss: 0.0473, Accuracy: 98.00%\n",
      "Epoch [4/20], Step [500/1260], Loss: 0.1196, Accuracy: 97.00%\n",
      "Epoch [4/20], Step [600/1260], Loss: 0.0521, Accuracy: 98.00%\n",
      "Epoch [4/20], Step [700/1260], Loss: 0.1034, Accuracy: 98.00%\n",
      "Epoch [4/20], Step [800/1260], Loss: 0.1744, Accuracy: 95.00%\n",
      "Epoch [4/20], Step [900/1260], Loss: 0.0390, Accuracy: 98.00%\n",
      "Epoch [4/20], Step [1000/1260], Loss: 0.0481, Accuracy: 99.00%\n",
      "Epoch [4/20], Step [1100/1260], Loss: 0.1289, Accuracy: 95.00%\n",
      "Epoch [4/20], Step [1200/1260], Loss: 0.0689, Accuracy: 98.00%\n",
      "Epoch [5/20], Step [100/1260], Loss: 0.0631, Accuracy: 97.00%\n",
      "Epoch [5/20], Step [200/1260], Loss: 0.0350, Accuracy: 99.00%\n",
      "Epoch [5/20], Step [300/1260], Loss: 0.0309, Accuracy: 98.00%\n",
      "Epoch [5/20], Step [400/1260], Loss: 0.0248, Accuracy: 99.00%\n",
      "Epoch [5/20], Step [500/1260], Loss: 0.0593, Accuracy: 98.00%\n",
      "Epoch [5/20], Step [600/1260], Loss: 0.0532, Accuracy: 98.00%\n",
      "Epoch [5/20], Step [700/1260], Loss: 0.0801, Accuracy: 98.00%\n",
      "Epoch [5/20], Step [800/1260], Loss: 0.1459, Accuracy: 95.00%\n",
      "Epoch [5/20], Step [900/1260], Loss: 0.0590, Accuracy: 99.00%\n",
      "Epoch [5/20], Step [1000/1260], Loss: 0.0600, Accuracy: 97.00%\n",
      "Epoch [5/20], Step [1100/1260], Loss: 0.0589, Accuracy: 99.00%\n",
      "Epoch [5/20], Step [1200/1260], Loss: 0.0613, Accuracy: 97.00%\n",
      "Epoch [6/20], Step [100/1260], Loss: 0.0235, Accuracy: 100.00%\n",
      "Epoch [6/20], Step [200/1260], Loss: 0.0880, Accuracy: 96.00%\n",
      "Epoch [6/20], Step [300/1260], Loss: 0.0291, Accuracy: 100.00%\n",
      "Epoch [6/20], Step [400/1260], Loss: 0.0712, Accuracy: 98.00%\n",
      "Epoch [6/20], Step [500/1260], Loss: 0.1529, Accuracy: 96.00%\n",
      "Epoch [6/20], Step [600/1260], Loss: 0.0819, Accuracy: 98.00%\n",
      "Epoch [6/20], Step [700/1260], Loss: 0.0312, Accuracy: 99.00%\n",
      "Epoch [6/20], Step [800/1260], Loss: 0.0131, Accuracy: 100.00%\n",
      "Epoch [6/20], Step [900/1260], Loss: 0.0404, Accuracy: 100.00%\n",
      "Epoch [6/20], Step [1000/1260], Loss: 0.0730, Accuracy: 98.00%\n",
      "Epoch [6/20], Step [1100/1260], Loss: 0.0452, Accuracy: 98.00%\n",
      "Epoch [6/20], Step [1200/1260], Loss: 0.0370, Accuracy: 99.00%\n",
      "Epoch [7/20], Step [100/1260], Loss: 0.0300, Accuracy: 98.00%\n",
      "Epoch [7/20], Step [200/1260], Loss: 0.1104, Accuracy: 97.00%\n",
      "Epoch [7/20], Step [300/1260], Loss: 0.0769, Accuracy: 96.00%\n",
      "Epoch [7/20], Step [400/1260], Loss: 0.0277, Accuracy: 99.00%\n",
      "Epoch [7/20], Step [500/1260], Loss: 0.0349, Accuracy: 98.00%\n",
      "Epoch [7/20], Step [600/1260], Loss: 0.0624, Accuracy: 98.00%\n",
      "Epoch [7/20], Step [700/1260], Loss: 0.0821, Accuracy: 97.00%\n",
      "Epoch [7/20], Step [800/1260], Loss: 0.0267, Accuracy: 99.00%\n",
      "Epoch [7/20], Step [900/1260], Loss: 0.0341, Accuracy: 99.00%\n",
      "Epoch [7/20], Step [1000/1260], Loss: 0.1406, Accuracy: 96.00%\n",
      "Epoch [7/20], Step [1100/1260], Loss: 0.0798, Accuracy: 97.00%\n",
      "Epoch [7/20], Step [1200/1260], Loss: 0.0481, Accuracy: 98.00%\n",
      "Epoch [8/20], Step [100/1260], Loss: 0.0994, Accuracy: 97.00%\n",
      "Epoch [8/20], Step [200/1260], Loss: 0.0268, Accuracy: 100.00%\n",
      "Epoch [8/20], Step [300/1260], Loss: 0.0285, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [400/1260], Loss: 0.0227, Accuracy: 100.00%\n",
      "Epoch [8/20], Step [500/1260], Loss: 0.0219, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [600/1260], Loss: 0.0155, Accuracy: 100.00%\n",
      "Epoch [8/20], Step [700/1260], Loss: 0.0244, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [800/1260], Loss: 0.0333, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [900/1260], Loss: 0.0524, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [1000/1260], Loss: 0.0392, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [1100/1260], Loss: 0.0463, Accuracy: 99.00%\n",
      "Epoch [8/20], Step [1200/1260], Loss: 0.0115, Accuracy: 100.00%\n",
      "Epoch [9/20], Step [100/1260], Loss: 0.0418, Accuracy: 97.00%\n",
      "Epoch [9/20], Step [200/1260], Loss: 0.0222, Accuracy: 98.00%\n",
      "Epoch [9/20], Step [300/1260], Loss: 0.0165, Accuracy: 100.00%\n",
      "Epoch [9/20], Step [400/1260], Loss: 0.0232, Accuracy: 98.00%\n",
      "Epoch [9/20], Step [500/1260], Loss: 0.0378, Accuracy: 99.00%\n",
      "Epoch [9/20], Step [600/1260], Loss: 0.1022, Accuracy: 94.00%\n",
      "Epoch [9/20], Step [700/1260], Loss: 0.0145, Accuracy: 100.00%\n",
      "Epoch [9/20], Step [800/1260], Loss: 0.0358, Accuracy: 99.00%\n",
      "Epoch [9/20], Step [900/1260], Loss: 0.0144, Accuracy: 99.00%\n",
      "Epoch [9/20], Step [1000/1260], Loss: 0.0334, Accuracy: 99.00%\n",
      "Epoch [9/20], Step [1100/1260], Loss: 0.0071, Accuracy: 100.00%\n",
      "Epoch [9/20], Step [1200/1260], Loss: 0.0110, Accuracy: 100.00%\n",
      "Epoch [10/20], Step [100/1260], Loss: 0.0081, Accuracy: 100.00%\n",
      "Epoch [10/20], Step [200/1260], Loss: 0.0918, Accuracy: 98.00%\n",
      "Epoch [10/20], Step [300/1260], Loss: 0.0301, Accuracy: 99.00%\n",
      "Epoch [10/20], Step [400/1260], Loss: 0.0325, Accuracy: 99.00%\n",
      "Epoch [10/20], Step [500/1260], Loss: 0.0354, Accuracy: 98.00%\n",
      "Epoch [10/20], Step [600/1260], Loss: 0.0781, Accuracy: 98.00%\n",
      "Epoch [10/20], Step [700/1260], Loss: 0.0128, Accuracy: 100.00%\n",
      "Epoch [10/20], Step [800/1260], Loss: 0.0422, Accuracy: 98.00%\n",
      "Epoch [10/20], Step [900/1260], Loss: 0.0273, Accuracy: 99.00%\n",
      "Epoch [10/20], Step [1000/1260], Loss: 0.0169, Accuracy: 100.00%\n",
      "Epoch [10/20], Step [1100/1260], Loss: 0.0165, Accuracy: 100.00%\n",
      "Epoch [10/20], Step [1200/1260], Loss: 0.0232, Accuracy: 99.00%\n",
      "Epoch [11/20], Step [100/1260], Loss: 0.1092, Accuracy: 98.00%\n",
      "Epoch [11/20], Step [200/1260], Loss: 0.0318, Accuracy: 98.00%\n",
      "Epoch [11/20], Step [300/1260], Loss: 0.0131, Accuracy: 100.00%\n",
      "Epoch [11/20], Step [400/1260], Loss: 0.0247, Accuracy: 99.00%\n",
      "Epoch [11/20], Step [500/1260], Loss: 0.0373, Accuracy: 98.00%\n",
      "Epoch [11/20], Step [600/1260], Loss: 0.1235, Accuracy: 98.00%\n",
      "Epoch [11/20], Step [700/1260], Loss: 0.0121, Accuracy: 100.00%\n",
      "Epoch [11/20], Step [800/1260], Loss: 0.0469, Accuracy: 98.00%\n",
      "Epoch [11/20], Step [900/1260], Loss: 0.0101, Accuracy: 100.00%\n",
      "Epoch [11/20], Step [1000/1260], Loss: 0.0118, Accuracy: 99.00%\n",
      "Epoch [11/20], Step [1100/1260], Loss: 0.0277, Accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Step [1200/1260], Loss: 0.0184, Accuracy: 99.00%\n",
      "Epoch [12/20], Step [100/1260], Loss: 0.0391, Accuracy: 98.00%\n",
      "Epoch [12/20], Step [200/1260], Loss: 0.0098, Accuracy: 100.00%\n",
      "Epoch [12/20], Step [300/1260], Loss: 0.0277, Accuracy: 98.00%\n",
      "Epoch [12/20], Step [400/1260], Loss: 0.0089, Accuracy: 100.00%\n",
      "Epoch [12/20], Step [500/1260], Loss: 0.0107, Accuracy: 100.00%\n",
      "Epoch [12/20], Step [600/1260], Loss: 0.0606, Accuracy: 99.00%\n",
      "Epoch [12/20], Step [700/1260], Loss: 0.0285, Accuracy: 98.00%\n",
      "Epoch [12/20], Step [800/1260], Loss: 0.0474, Accuracy: 98.00%\n",
      "Epoch [12/20], Step [900/1260], Loss: 0.0059, Accuracy: 100.00%\n",
      "Epoch [12/20], Step [1000/1260], Loss: 0.0165, Accuracy: 99.00%\n",
      "Epoch [12/20], Step [1100/1260], Loss: 0.0140, Accuracy: 100.00%\n",
      "Epoch [12/20], Step [1200/1260], Loss: 0.0192, Accuracy: 99.00%\n",
      "Epoch [13/20], Step [100/1260], Loss: 0.0377, Accuracy: 99.00%\n",
      "Epoch [13/20], Step [200/1260], Loss: 0.0430, Accuracy: 98.00%\n",
      "Epoch [13/20], Step [300/1260], Loss: 0.0182, Accuracy: 100.00%\n",
      "Epoch [13/20], Step [400/1260], Loss: 0.0196, Accuracy: 100.00%\n",
      "Epoch [13/20], Step [500/1260], Loss: 0.0277, Accuracy: 99.00%\n",
      "Epoch [13/20], Step [600/1260], Loss: 0.0624, Accuracy: 96.00%\n",
      "Epoch [13/20], Step [700/1260], Loss: 0.0181, Accuracy: 99.00%\n",
      "Epoch [13/20], Step [800/1260], Loss: 0.0153, Accuracy: 100.00%\n",
      "Epoch [13/20], Step [900/1260], Loss: 0.0198, Accuracy: 99.00%\n",
      "Epoch [13/20], Step [1000/1260], Loss: 0.0902, Accuracy: 98.00%\n",
      "Epoch [13/20], Step [1100/1260], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [13/20], Step [1200/1260], Loss: 0.0310, Accuracy: 99.00%\n",
      "Epoch [14/20], Step [100/1260], Loss: 0.0296, Accuracy: 100.00%\n",
      "Epoch [14/20], Step [200/1260], Loss: 0.1495, Accuracy: 98.00%\n",
      "Epoch [14/20], Step [300/1260], Loss: 0.0284, Accuracy: 98.00%\n",
      "Epoch [14/20], Step [400/1260], Loss: 0.0745, Accuracy: 98.00%\n",
      "Epoch [14/20], Step [500/1260], Loss: 0.0307, Accuracy: 98.00%\n",
      "Epoch [14/20], Step [600/1260], Loss: 0.0140, Accuracy: 99.00%\n",
      "Epoch [14/20], Step [700/1260], Loss: 0.0078, Accuracy: 100.00%\n",
      "Epoch [14/20], Step [800/1260], Loss: 0.0206, Accuracy: 99.00%\n",
      "Epoch [14/20], Step [900/1260], Loss: 0.0223, Accuracy: 99.00%\n",
      "Epoch [14/20], Step [1000/1260], Loss: 0.0889, Accuracy: 97.00%\n",
      "Epoch [14/20], Step [1100/1260], Loss: 0.0300, Accuracy: 99.00%\n",
      "Epoch [14/20], Step [1200/1260], Loss: 0.0231, Accuracy: 99.00%\n",
      "Epoch [15/20], Step [100/1260], Loss: 0.0276, Accuracy: 99.00%\n",
      "Epoch [15/20], Step [200/1260], Loss: 0.0194, Accuracy: 100.00%\n",
      "Epoch [15/20], Step [300/1260], Loss: 0.0392, Accuracy: 99.00%\n",
      "Epoch [15/20], Step [400/1260], Loss: 0.0143, Accuracy: 99.00%\n",
      "Epoch [15/20], Step [500/1260], Loss: 0.0090, Accuracy: 100.00%\n",
      "Epoch [15/20], Step [600/1260], Loss: 0.0141, Accuracy: 100.00%\n",
      "Epoch [15/20], Step [700/1260], Loss: 0.0134, Accuracy: 99.00%\n",
      "Epoch [15/20], Step [800/1260], Loss: 0.0194, Accuracy: 100.00%\n",
      "Epoch [15/20], Step [900/1260], Loss: 0.0780, Accuracy: 97.00%\n",
      "Epoch [15/20], Step [1000/1260], Loss: 0.0213, Accuracy: 100.00%\n",
      "Epoch [15/20], Step [1100/1260], Loss: 0.1122, Accuracy: 97.00%\n",
      "Epoch [15/20], Step [1200/1260], Loss: 0.0086, Accuracy: 100.00%\n",
      "Epoch [16/20], Step [100/1260], Loss: 0.0903, Accuracy: 99.00%\n",
      "Epoch [16/20], Step [200/1260], Loss: 0.0067, Accuracy: 100.00%\n",
      "Epoch [16/20], Step [300/1260], Loss: 0.0109, Accuracy: 100.00%\n",
      "Epoch [16/20], Step [400/1260], Loss: 0.1493, Accuracy: 98.00%\n",
      "Epoch [16/20], Step [500/1260], Loss: 0.0296, Accuracy: 99.00%\n",
      "Epoch [16/20], Step [600/1260], Loss: 0.0448, Accuracy: 98.00%\n",
      "Epoch [16/20], Step [700/1260], Loss: 0.0564, Accuracy: 97.00%\n",
      "Epoch [16/20], Step [800/1260], Loss: 0.0533, Accuracy: 97.00%\n",
      "Epoch [16/20], Step [900/1260], Loss: 0.0306, Accuracy: 99.00%\n",
      "Epoch [16/20], Step [1000/1260], Loss: 0.0910, Accuracy: 95.00%\n",
      "Epoch [16/20], Step [1100/1260], Loss: 0.0342, Accuracy: 98.00%\n",
      "Epoch [16/20], Step [1200/1260], Loss: 0.0155, Accuracy: 100.00%\n",
      "Epoch [17/20], Step [100/1260], Loss: 0.0301, Accuracy: 99.00%\n",
      "Epoch [17/20], Step [200/1260], Loss: 0.0350, Accuracy: 98.00%\n",
      "Epoch [17/20], Step [300/1260], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [17/20], Step [400/1260], Loss: 0.0186, Accuracy: 100.00%\n",
      "Epoch [17/20], Step [500/1260], Loss: 0.0441, Accuracy: 98.00%\n",
      "Epoch [17/20], Step [600/1260], Loss: 0.0329, Accuracy: 98.00%\n",
      "Epoch [17/20], Step [700/1260], Loss: 0.0530, Accuracy: 98.00%\n",
      "Epoch [17/20], Step [800/1260], Loss: 0.0261, Accuracy: 99.00%\n",
      "Epoch [17/20], Step [900/1260], Loss: 0.0089, Accuracy: 100.00%\n",
      "Epoch [17/20], Step [1000/1260], Loss: 0.0117, Accuracy: 99.00%\n",
      "Epoch [17/20], Step [1100/1260], Loss: 0.0250, Accuracy: 99.00%\n",
      "Epoch [17/20], Step [1200/1260], Loss: 0.0432, Accuracy: 98.00%\n",
      "Epoch [18/20], Step [100/1260], Loss: 0.0542, Accuracy: 99.00%\n",
      "Epoch [18/20], Step [200/1260], Loss: 0.0702, Accuracy: 98.00%\n",
      "Epoch [18/20], Step [300/1260], Loss: 0.0062, Accuracy: 100.00%\n",
      "Epoch [18/20], Step [400/1260], Loss: 0.1560, Accuracy: 99.00%\n",
      "Epoch [18/20], Step [500/1260], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [18/20], Step [600/1260], Loss: 0.0057, Accuracy: 100.00%\n",
      "Epoch [18/20], Step [700/1260], Loss: 0.0460, Accuracy: 97.00%\n",
      "Epoch [18/20], Step [800/1260], Loss: 0.0260, Accuracy: 99.00%\n",
      "Epoch [18/20], Step [900/1260], Loss: 0.0896, Accuracy: 97.00%\n",
      "Epoch [18/20], Step [1000/1260], Loss: 0.0811, Accuracy: 96.00%\n",
      "Epoch [18/20], Step [1100/1260], Loss: 0.1225, Accuracy: 98.00%\n",
      "Epoch [18/20], Step [1200/1260], Loss: 0.1117, Accuracy: 97.00%\n",
      "Epoch [19/20], Step [100/1260], Loss: 0.0374, Accuracy: 98.00%\n",
      "Epoch [19/20], Step [200/1260], Loss: 0.0248, Accuracy: 98.00%\n",
      "Epoch [19/20], Step [300/1260], Loss: 0.0393, Accuracy: 98.00%\n",
      "Epoch [19/20], Step [400/1260], Loss: 0.0373, Accuracy: 98.00%\n",
      "Epoch [19/20], Step [500/1260], Loss: 0.0242, Accuracy: 99.00%\n",
      "Epoch [19/20], Step [600/1260], Loss: 0.0412, Accuracy: 98.00%\n",
      "Epoch [19/20], Step [700/1260], Loss: 0.0090, Accuracy: 100.00%\n",
      "Epoch [19/20], Step [800/1260], Loss: 0.0520, Accuracy: 98.00%\n",
      "Epoch [19/20], Step [900/1260], Loss: 0.0238, Accuracy: 100.00%\n",
      "Epoch [19/20], Step [1000/1260], Loss: 0.0341, Accuracy: 99.00%\n",
      "Epoch [19/20], Step [1100/1260], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [19/20], Step [1200/1260], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [20/20], Step [100/1260], Loss: 0.0133, Accuracy: 100.00%\n",
      "Epoch [20/20], Step [200/1260], Loss: 0.0801, Accuracy: 98.00%\n",
      "Epoch [20/20], Step [300/1260], Loss: 0.0471, Accuracy: 99.00%\n",
      "Epoch [20/20], Step [400/1260], Loss: 0.0413, Accuracy: 99.00%\n",
      "Epoch [20/20], Step [500/1260], Loss: 0.0531, Accuracy: 97.00%\n",
      "Epoch [20/20], Step [600/1260], Loss: 0.0171, Accuracy: 100.00%\n",
      "Epoch [20/20], Step [700/1260], Loss: 0.0104, Accuracy: 100.00%\n",
      "Epoch [20/20], Step [800/1260], Loss: 0.0207, Accuracy: 99.00%\n",
      "Epoch [20/20], Step [900/1260], Loss: 0.0147, Accuracy: 100.00%\n",
      "Epoch [20/20], Step [1000/1260], Loss: 0.0345, Accuracy: 98.00%\n",
      "Epoch [20/20], Step [1100/1260], Loss: 0.0468, Accuracy: 98.00%\n",
      "Epoch [20/20], Step [1200/1260], Loss: 0.0339, Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 99.32763369928477 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_loader = torch.utils.data.DataLoader(my_dataset, batch_size=P, shuffle=False) # create your dataloader\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model: {} %'.format((correct / total) * 100))\n",
    "\n",
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model_KDD_bin-5E.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Precision is: 0.9968040964068156\n",
      "\n",
      "**Confusion matrix is:\n",
      " [[67080    27     5   158    73]\n",
      " [   99 45828     0     0     0]\n",
      " [   25     0    26     1     0]\n",
      " [  197     1     2   791     4]\n",
      " [  245    10     0     0 11401]]\n",
      "\n",
      "**Classification report is:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     67343\n",
      "           1       1.00      1.00      1.00     45927\n",
      "           2       0.79      0.50      0.61        52\n",
      "           3       0.83      0.79      0.81       995\n",
      "           4       0.99      0.98      0.99     11656\n",
      "\n",
      "    accuracy                           0.99    125973\n",
      "   macro avg       0.92      0.85      0.88    125973\n",
      "weighted avg       0.99      0.99      0.99    125973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate the confusion matrix showing prediction and accuracy for each class\n",
    "\n",
    "import scoring\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "cm=metrics.confusion_matrix(tensor_y, predicted)\n",
    "print('**Precision is:',(cm[0][0]+cm[1][1])/(sum(cm[0])+sum(cm[1])))\n",
    "print('\\n**Confusion matrix is:\\n',cm)\n",
    "print('\\n**Classification report is:\\n',metrics.classification_report(tensor_y, predicted, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#turn the confusion matrix data into a heat map\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# set the labels according to \n",
    "if class_mode == 1:\n",
    "    class_labels = [\"Normal\",\"Attack\"]\n",
    "if class_mode == 2:\n",
    "    class_labels = [\"Normal\",\"DoS\",\"U2R\",\"R2L\",\"Probe\"]\n",
    "if class_mode == 3:\n",
    "    class_labels = [\"back\", \"buffer_overflow\", \"ftp_write\", \"guess_passwd\", \"imap\", \"ipsweep\", \"land\", \"loadmodule\", \n",
    "                    \"multihop\", \"neptune\", \"nmap\", \"normal\", \"perl\", \"phf\", \"pod\", \"portsweep\", \"rootkit\", \"satan\", \n",
    "                    \"smurf\", \"spy\", \"teardrop\", \"warezclient\", \"warezmaster\"]\n",
    "    \n",
    "                \n",
    "df_cm = pd.DataFrame(cm, index = [i for i in class_labels],\n",
    "              columns = [i for i in class_labels])\n",
    "plt.figure(figsize = (18,8))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"Blues\", fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "data = scipy.io.loadmat(\"nsl_kdd_pytorch.mat\")\n",
    "\n",
    "for i in data:\n",
    "    if '__' not in i and 'readme' not in i:\n",
    "            np.savetxt((\"nsl_kdd_pytorch.csv\"),data[i],delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
